{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hornh\\user_root\\venvs\\cv_prakt_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms, datasets, models\n",
    "from torchmetrics.classification import BinaryAccuracy, BinaryF1Score\n",
    "from torchmetrics.utilities.data import dim_zero_cat\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the paths to the train and test data folders\n",
    "DATA_DIR = r'..\\data'\n",
    "\n",
    "# Define a transform to preprocess the images (resize and normalize without standardization)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),  # Convert to grayscale\n",
    "    transforms.Resize((256, 256)),  # Resize the images to a fixed size\n",
    "    transforms.RandomRotation((-10, 10)),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize the images (mean and std for grayscale images)\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),  # Convert to grayscale\n",
    "    transforms.Resize((256, 256)),  # Resize the images to a fixed size\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize the images (mean and std for grayscale images)\n",
    "])\n",
    "\n",
    "# Create datasets for train and test\n",
    "train_dataset = datasets.ImageFolder(root=DATA_DIR + '/train', transform=train_transform)\n",
    "val_dataset = datasets.ImageFolder(root=DATA_DIR + '/train', transform=val_test_transform)\n",
    "test_dataset = datasets.ImageFolder(root=DATA_DIR + '/test', transform=val_test_transform)\n",
    "\n",
    "\n",
    "train_indices, val_indices = train_test_split(torch.arange(len(train_dataset)), test_size=0.15, random_state=42)\n",
    "train_dataset = torch.utils.data.Subset(train_dataset, train_indices)\n",
    "val_dataset = torch.utils.data.Subset(val_dataset, val_indices)\n",
    "\n",
    "# Create DataLoaders for train and test datasets\n",
    "batch_size = 8\n",
    "# initial_train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=len(train_dataset), shuffle=True, pin_memory=True, num_workers=4)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=4)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(555, 98, 78, 4433, 783, 624)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), len(val_loader), len(test_loader), len(train_dataset), len(val_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not used\n",
    "class CustomTensorDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, transform):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data (List[torch.Tensor]): The preloaded list of tensors containing your inputs and labels.\n",
    "        \"\"\"\n",
    "        self.inputs = data[0]\n",
    "        self.labels = data[1]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        item = [self.inputs[index], self.labels[index]]\n",
    "        return item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the models and change the architecture such that they take grayscale images and add a new classification head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Convnext Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "convnext = models.convnext_tiny(weights='DEFAULT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all the pre-trained layers\n",
    "for param in convnext.parameters():\n",
    "   param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNeXt(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
       "      (1): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=96, out_features=384, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=384, out_features=96, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "      )\n",
       "      (1): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=96, out_features=384, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=384, out_features=96, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0058823529411764705, mode=row)\n",
       "      )\n",
       "      (2): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=96, out_features=384, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=384, out_features=96, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.011764705882352941, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n",
       "      (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=192, out_features=768, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=768, out_features=192, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.017647058823529415, mode=row)\n",
       "      )\n",
       "      (1): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=192, out_features=768, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=768, out_features=192, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.023529411764705882, mode=row)\n",
       "      )\n",
       "      (2): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=192, out_features=768, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=768, out_features=192, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.029411764705882353, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.03529411764705883, mode=row)\n",
       "      )\n",
       "      (1): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0411764705882353, mode=row)\n",
       "      )\n",
       "      (2): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.047058823529411764, mode=row)\n",
       "      )\n",
       "      (3): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.052941176470588235, mode=row)\n",
       "      )\n",
       "      (4): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.058823529411764705, mode=row)\n",
       "      )\n",
       "      (5): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.06470588235294118, mode=row)\n",
       "      )\n",
       "      (6): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.07058823529411766, mode=row)\n",
       "      )\n",
       "      (7): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.07647058823529412, mode=row)\n",
       "      )\n",
       "      (8): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0823529411764706, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.08823529411764706, mode=row)\n",
       "      )\n",
       "      (1): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.09411764705882353, mode=row)\n",
       "      )\n",
       "      (2): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): LayerNorm2d((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (1): Flatten(start_dim=1, end_dim=-1)\n",
       "    (2): Linear(in_features=768, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convnext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['features.0.0.weight', 'features.0.0.bias', 'features.0.1.weight', 'features.0.1.bias', 'features.1.0.layer_scale', 'features.1.0.block.0.weight', 'features.1.0.block.0.bias', 'features.1.0.block.2.weight', 'features.1.0.block.2.bias', 'features.1.0.block.3.weight', 'features.1.0.block.3.bias', 'features.1.0.block.5.weight', 'features.1.0.block.5.bias', 'features.1.1.layer_scale', 'features.1.1.block.0.weight', 'features.1.1.block.0.bias', 'features.1.1.block.2.weight', 'features.1.1.block.2.bias', 'features.1.1.block.3.weight', 'features.1.1.block.3.bias', 'features.1.1.block.5.weight', 'features.1.1.block.5.bias', 'features.1.2.layer_scale', 'features.1.2.block.0.weight', 'features.1.2.block.0.bias', 'features.1.2.block.2.weight', 'features.1.2.block.2.bias', 'features.1.2.block.3.weight', 'features.1.2.block.3.bias', 'features.1.2.block.5.weight', 'features.1.2.block.5.bias', 'features.2.0.weight', 'features.2.0.bias', 'features.2.1.weight', 'features.2.1.bias', 'features.3.0.layer_scale', 'features.3.0.block.0.weight', 'features.3.0.block.0.bias', 'features.3.0.block.2.weight', 'features.3.0.block.2.bias', 'features.3.0.block.3.weight', 'features.3.0.block.3.bias', 'features.3.0.block.5.weight', 'features.3.0.block.5.bias', 'features.3.1.layer_scale', 'features.3.1.block.0.weight', 'features.3.1.block.0.bias', 'features.3.1.block.2.weight', 'features.3.1.block.2.bias', 'features.3.1.block.3.weight', 'features.3.1.block.3.bias', 'features.3.1.block.5.weight', 'features.3.1.block.5.bias', 'features.3.2.layer_scale', 'features.3.2.block.0.weight', 'features.3.2.block.0.bias', 'features.3.2.block.2.weight', 'features.3.2.block.2.bias', 'features.3.2.block.3.weight', 'features.3.2.block.3.bias', 'features.3.2.block.5.weight', 'features.3.2.block.5.bias', 'features.4.0.weight', 'features.4.0.bias', 'features.4.1.weight', 'features.4.1.bias', 'features.5.0.layer_scale', 'features.5.0.block.0.weight', 'features.5.0.block.0.bias', 'features.5.0.block.2.weight', 'features.5.0.block.2.bias', 'features.5.0.block.3.weight', 'features.5.0.block.3.bias', 'features.5.0.block.5.weight', 'features.5.0.block.5.bias', 'features.5.1.layer_scale', 'features.5.1.block.0.weight', 'features.5.1.block.0.bias', 'features.5.1.block.2.weight', 'features.5.1.block.2.bias', 'features.5.1.block.3.weight', 'features.5.1.block.3.bias', 'features.5.1.block.5.weight', 'features.5.1.block.5.bias', 'features.5.2.layer_scale', 'features.5.2.block.0.weight', 'features.5.2.block.0.bias', 'features.5.2.block.2.weight', 'features.5.2.block.2.bias', 'features.5.2.block.3.weight', 'features.5.2.block.3.bias', 'features.5.2.block.5.weight', 'features.5.2.block.5.bias', 'features.5.3.layer_scale', 'features.5.3.block.0.weight', 'features.5.3.block.0.bias', 'features.5.3.block.2.weight', 'features.5.3.block.2.bias', 'features.5.3.block.3.weight', 'features.5.3.block.3.bias', 'features.5.3.block.5.weight', 'features.5.3.block.5.bias', 'features.5.4.layer_scale', 'features.5.4.block.0.weight', 'features.5.4.block.0.bias', 'features.5.4.block.2.weight', 'features.5.4.block.2.bias', 'features.5.4.block.3.weight', 'features.5.4.block.3.bias', 'features.5.4.block.5.weight', 'features.5.4.block.5.bias', 'features.5.5.layer_scale', 'features.5.5.block.0.weight', 'features.5.5.block.0.bias', 'features.5.5.block.2.weight', 'features.5.5.block.2.bias', 'features.5.5.block.3.weight', 'features.5.5.block.3.bias', 'features.5.5.block.5.weight', 'features.5.5.block.5.bias', 'features.5.6.layer_scale', 'features.5.6.block.0.weight', 'features.5.6.block.0.bias', 'features.5.6.block.2.weight', 'features.5.6.block.2.bias', 'features.5.6.block.3.weight', 'features.5.6.block.3.bias', 'features.5.6.block.5.weight', 'features.5.6.block.5.bias', 'features.5.7.layer_scale', 'features.5.7.block.0.weight', 'features.5.7.block.0.bias', 'features.5.7.block.2.weight', 'features.5.7.block.2.bias', 'features.5.7.block.3.weight', 'features.5.7.block.3.bias', 'features.5.7.block.5.weight', 'features.5.7.block.5.bias', 'features.5.8.layer_scale', 'features.5.8.block.0.weight', 'features.5.8.block.0.bias', 'features.5.8.block.2.weight', 'features.5.8.block.2.bias', 'features.5.8.block.3.weight', 'features.5.8.block.3.bias', 'features.5.8.block.5.weight', 'features.5.8.block.5.bias', 'features.6.0.weight', 'features.6.0.bias', 'features.6.1.weight', 'features.6.1.bias', 'features.7.0.layer_scale', 'features.7.0.block.0.weight', 'features.7.0.block.0.bias', 'features.7.0.block.2.weight', 'features.7.0.block.2.bias', 'features.7.0.block.3.weight', 'features.7.0.block.3.bias', 'features.7.0.block.5.weight', 'features.7.0.block.5.bias', 'features.7.1.layer_scale', 'features.7.1.block.0.weight', 'features.7.1.block.0.bias', 'features.7.1.block.2.weight', 'features.7.1.block.2.bias', 'features.7.1.block.3.weight', 'features.7.1.block.3.bias', 'features.7.1.block.5.weight', 'features.7.1.block.5.bias', 'features.7.2.layer_scale', 'features.7.2.block.0.weight', 'features.7.2.block.0.bias', 'features.7.2.block.2.weight', 'features.7.2.block.2.bias', 'features.7.2.block.3.weight', 'features.7.2.block.3.bias', 'features.7.2.block.5.weight', 'features.7.2.block.5.bias', 'classifier.0.weight', 'classifier.0.bias', 'classifier.2.weight', 'classifier.2.bias'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = convnext.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([96, 3, 4, 4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict['features.0.0.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_cov_weights = state_dict['features.0.0.weight']\n",
    "state_dict['features.0.0.weight'] = first_cov_weights.sum(dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([96, 1, 4, 4])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict['features.0.0.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([96, 3, 4, 4])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convnext.state_dict()['features.0.0.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convnext.features[0][0] = nn.Conv2d(1, 96, kernel_size=(4,4), stride=(4,4))\n",
    "convnext.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): LayerNorm2d((768,), eps=1e-06, elementwise_affine=True)\n",
       "  (1): Flatten(start_dim=1, end_dim=-1)\n",
       "  (2): Linear(in_features=768, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convnext.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "convnext.classifier[2] = nn.Sequential(\n",
    "    nn.Linear(in_features=768, out_features=512),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(in_features=512, out_features=128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(in_features=128, out_features=1),\n",
    "    nn.Sigmoid(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0140,  0.0028,  0.0242,  ..., -0.0270, -0.0256,  0.0099],\n",
       "        [-0.0295, -0.0324, -0.0196,  ..., -0.0115,  0.0142, -0.0328],\n",
       "        [ 0.0230,  0.0194, -0.0321,  ...,  0.0086,  0.0261,  0.0320],\n",
       "        ...,\n",
       "        [ 0.0220, -0.0158,  0.0016,  ..., -0.0260, -0.0055, -0.0259],\n",
       "        [ 0.0170,  0.0310, -0.0176,  ..., -0.0282, -0.0292,  0.0321],\n",
       "        [-0.0072, -0.0256,  0.0234,  ...,  0.0328, -0.0232, -0.0278]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convnext.classifier[2][0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convnext.classifier[0].weight.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\hornh/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      "c:\\Users\\hornh\\user_root\\venvs\\cv_prakt_env\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\hornh\\user_root\\venvs\\cv_prakt_env\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "resnet = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Freeze all the pre-trained layers\n",
    "for param in resnet.parameters():\n",
    "   param.requires_grad = False\n",
    "\n",
    "# change first layer to grayscale\n",
    "state_dict2 = resnet.state_dict()\n",
    "state_dict2['conv1.weight'] = state_dict2['conv1.weight'].sum(dim=1, keepdim=True)\n",
    "resnet.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "resnet.load_state_dict(state_dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add classification head\n",
    "resnet.fc = nn.Sequential(\n",
    "    nn.Linear(in_features=512, out_features=256),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(in_features=256, out_features=128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(in_features=128, out_features=1),\n",
    "    nn.Sigmoid(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=128, out_features=1, bias=True)\n",
       "    (7): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\hornh/.cache\\torch\\hub\\NVIDIA_DeepLearningExamples_torchhub\n",
      "C:\\Users\\hornh/.cache\\torch\\hub\\NVIDIA_DeepLearningExamples_torchhub\\PyTorch\\Classification\\ConvNets\\image_classification\\models\\common.py:13: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
      "  warnings.warn(\n",
      "C:\\Users\\hornh/.cache\\torch\\hub\\NVIDIA_DeepLearningExamples_torchhub\\PyTorch\\Classification\\ConvNets\\image_classification\\models\\efficientnet.py:17: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (stem): Sequential(\n",
       "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (activation): SiLU(inplace=True)\n",
       "  )\n",
       "  (layers): Sequential(\n",
       "    (0): Sequential(\n",
       "      (block0): MBConvBlock(\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=32, out_features=8, bias=True)\n",
       "          (expand): Linear(in_features=8, out_features=32, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (block0): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=96, out_features=4, bias=True)\n",
       "          (expand): Linear(in_features=4, out_features=96, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "      (block1): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (bn): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=144, out_features=6, bias=True)\n",
       "          (expand): Linear(in_features=6, out_features=144, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (block0): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
       "          (bn): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=144, out_features=6, bias=True)\n",
       "          (expand): Linear(in_features=6, out_features=144, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "      (block1): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "          (bn): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=240, out_features=10, bias=True)\n",
       "          (expand): Linear(in_features=10, out_features=240, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (block0): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "          (bn): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=240, out_features=10, bias=True)\n",
       "          (expand): Linear(in_features=10, out_features=240, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "      (block1): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "          (bn): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=480, out_features=20, bias=True)\n",
       "          (expand): Linear(in_features=20, out_features=480, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "      (block2): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "          (bn): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=480, out_features=20, bias=True)\n",
       "          (expand): Linear(in_features=20, out_features=480, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (block0): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "          (bn): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=480, out_features=20, bias=True)\n",
       "          (expand): Linear(in_features=20, out_features=480, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "      (block1): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "          (bn): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=672, out_features=28, bias=True)\n",
       "          (expand): Linear(in_features=28, out_features=672, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "      (block2): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "          (bn): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=672, out_features=28, bias=True)\n",
       "          (expand): Linear(in_features=28, out_features=672, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (block0): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "          (bn): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=672, out_features=28, bias=True)\n",
       "          (expand): Linear(in_features=28, out_features=672, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "      (block1): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "          (bn): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=1152, out_features=48, bias=True)\n",
       "          (expand): Linear(in_features=48, out_features=1152, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "      (block2): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "          (bn): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=1152, out_features=48, bias=True)\n",
       "          (expand): Linear(in_features=48, out_features=1152, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "      (block3): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "          (bn): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=1152, out_features=48, bias=True)\n",
       "          (expand): Linear(in_features=48, out_features=1152, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (block0): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "          (bn): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=1152, out_features=48, bias=True)\n",
       "          (expand): Linear(in_features=48, out_features=1152, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (features): Sequential(\n",
       "    (conv): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (activation): SiLU(inplace=True)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "    (squeeze): Flatten()\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "    (fc): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_b0', pretrained=True)\n",
    "efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet.stem[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all the pre-trained layers\n",
    "for param in efficientnet.parameters():\n",
    "   param.requires_grad = False\n",
    "\n",
    "# change first layer to grayscale\n",
    "effnet_state_dict = efficientnet.state_dict()\n",
    "effnet_state_dict['stem.conv.weight'] = effnet_state_dict['stem.conv.weight'].sum(dim=1, keepdim=True)\n",
    "efficientnet.stem.conv = nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "efficientnet.load_state_dict(effnet_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add classification head\n",
    "efficientnet.classifier.fc = nn.Sequential(\n",
    "    nn.Linear(in_features=1280, out_features=256),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(in_features=256, out_features=128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(in_features=128, out_features=1),\n",
    "    nn.Sigmoid(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (stem): Sequential(\n",
       "    (conv): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (activation): SiLU(inplace=True)\n",
       "  )\n",
       "  (layers): Sequential(\n",
       "    (0): Sequential(\n",
       "      (block0): MBConvBlock(\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=32, out_features=8, bias=True)\n",
       "          (expand): Linear(in_features=8, out_features=32, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (block0): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=96, out_features=4, bias=True)\n",
       "          (expand): Linear(in_features=4, out_features=96, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "      (block1): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (bn): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=144, out_features=6, bias=True)\n",
       "          (expand): Linear(in_features=6, out_features=144, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (block0): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
       "          (bn): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=144, out_features=6, bias=True)\n",
       "          (expand): Linear(in_features=6, out_features=144, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "      (block1): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "          (bn): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=240, out_features=10, bias=True)\n",
       "          (expand): Linear(in_features=10, out_features=240, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (block0): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "          (bn): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=240, out_features=10, bias=True)\n",
       "          (expand): Linear(in_features=10, out_features=240, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "      (block1): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "          (bn): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=480, out_features=20, bias=True)\n",
       "          (expand): Linear(in_features=20, out_features=480, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "      (block2): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "          (bn): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=480, out_features=20, bias=True)\n",
       "          (expand): Linear(in_features=20, out_features=480, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (block0): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "          (bn): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=480, out_features=20, bias=True)\n",
       "          (expand): Linear(in_features=20, out_features=480, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "      (block1): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "          (bn): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=672, out_features=28, bias=True)\n",
       "          (expand): Linear(in_features=28, out_features=672, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "      (block2): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "          (bn): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=672, out_features=28, bias=True)\n",
       "          (expand): Linear(in_features=28, out_features=672, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (block0): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "          (bn): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=672, out_features=28, bias=True)\n",
       "          (expand): Linear(in_features=28, out_features=672, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "      (block1): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "          (bn): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=1152, out_features=48, bias=True)\n",
       "          (expand): Linear(in_features=48, out_features=1152, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "      (block2): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "          (bn): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=1152, out_features=48, bias=True)\n",
       "          (expand): Linear(in_features=48, out_features=1152, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "      (block3): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "          (bn): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=1152, out_features=48, bias=True)\n",
       "          (expand): Linear(in_features=48, out_features=1152, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (block0): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "          (bn): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=1152, out_features=48, bias=True)\n",
       "          (expand): Linear(in_features=48, out_features=1152, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (features): Sequential(\n",
       "    (conv): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (activation): SiLU(inplace=True)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "    (squeeze): Flatten()\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=1280, out_features=256, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=128, out_features=1, bias=True)\n",
       "      (7): Sigmoid()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_confusion_matrix_plot(tp, fp, tn, fn):\n",
    "    df_cm = pd.DataFrame(torch.tensor([[tp, fp], [fn, tn]]), index=['normal', 'pneumonia'],\n",
    "                         columns=['normal', 'pneumonia'])\n",
    "    plt.figure(figsize=(12, 7))    \n",
    "    return sns.heatmap(df_cm, annot=True).get_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "accuracy_metric = BinaryAccuracy().to(device)\n",
    "f1_score_metric = BinaryF1Score().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n",
      "epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/555 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch num 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/555 [00:19<1:12:56,  7.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch num 1\n",
      "batch num 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 4/555 [00:19<24:59,  2.72s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch num 3\n",
      "batch num 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 5/555 [00:19<16:52,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch num 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/555 [00:20<11:54,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch num 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/555 [00:20<31:46,  3.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy tensor(0.7500, device='cuda:0')\n",
      "0.0007419497305777335 tensor(0.8462, device='cuda:0') tensor(0.7500, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/98 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "for model_idx, model in enumerate([convnext, resnet, efficientnet]):\n",
    "    model.to(device)\n",
    "\n",
    "    if model_idx == 2:\n",
    "        optimizer = torch.optim.Adam(model.classifier.fc.parameters(), lr=0.001)\n",
    "    elif model_idx == 1:\n",
    "        optimizer = torch.optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "    elif model_idx == 0:\n",
    "        continue\n",
    "\n",
    "    epochs = 4\n",
    "    writer = SummaryWriter()\n",
    "\n",
    "\n",
    "    for epoch in range(epochs):  \n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        f1_score_metric.reset() \n",
    "        accuracy_metric.reset()\n",
    "\n",
    "        print(\"---------------------\")\n",
    "        print('epoch', epoch)\n",
    "\n",
    "        for i, data in enumerate(tqdm(train_loader)):\n",
    "\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs).reshape(-1)\n",
    "            loss = criterion(outputs, labels.type(torch.float32))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            bin_outputs = torch.round(outputs)\n",
    "\n",
    "            \n",
    "            accuracy_metric.update(bin_outputs, labels)\n",
    "            f1_score_metric.update(bin_outputs, labels)\n",
    "\n",
    "\n",
    "        train_loss = running_loss/len(train_dataset)\n",
    "        train_f1 = f1_score_metric.compute()\n",
    "        accuracy = accuracy_metric.compute()\n",
    "        \n",
    "        writer.add_scalar('Train/Loss', train_loss, epoch)\n",
    "        writer.add_scalar('Train/F1-Score', train_f1, epoch)\n",
    "        writer.add_scalar('Train/Accuracy', accuracy, epoch)\n",
    "        \n",
    "        print(train_loss, train_f1, accuracy)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss, val_tp, val_fp, val_fn, val_correct = 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "            epoch_labels, epoch_predictions = [], []\n",
    "            f1_score_metric.reset()  \n",
    "            accuracy_metric.reset()\n",
    "\n",
    "            for data in tqdm(val_loader):\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(inputs).reshape(-1)\n",
    "                loss = criterion(outputs, labels.type(torch.float32))\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                bin_outputs = torch.round(outputs)\n",
    "\n",
    "                accuracy_metric.update(bin_outputs, labels)\n",
    "                f1_score_metric.update(bin_outputs, labels)\n",
    "                epoch_labels.append(labels)\n",
    "                epoch_predictions.append(outputs)\n",
    "                \n",
    "\n",
    "            val_loss = val_loss / len(val_dataset)\n",
    "            tp, fp, tn, fn = f1_score_metric.tp, f1_score_metric.fp, f1_score_metric.tn, f1_score_metric.fn\n",
    "            val_f1 = f1_score_metric.compute()\n",
    "            val_acc = accuracy_metric.compute()\n",
    "            # Log validation metrics to TensorBoard\n",
    "            writer.add_scalar('Validation/Loss', val_loss, epoch)\n",
    "            writer.add_scalar('Validation/F1-Score', val_f1, epoch)\n",
    "            writer.add_scalar('Validation/Accuracy', val_acc, epoch)\n",
    "            writer.add_pr_curve('pr_curve', dim_zero_cat(epoch_labels), dim_zero_cat(epoch_predictions), epoch)\n",
    "            writer.add_figure(\"Confusion matrix\", create_confusion_matrix_plot(tp, fp, tn, fn), epoch)\n",
    "        \n",
    "\n",
    "\n",
    "    torch.save(model, f'model_run_{model_idx}.pth')\n",
    "\n",
    "    writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_prakt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
